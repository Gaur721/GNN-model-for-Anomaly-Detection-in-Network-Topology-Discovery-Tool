{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlPSaq-Ft4gG",
        "outputId": "2ea56d0a-9328-4e79-bd83-effb357e43e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchaudio) (3.0.2)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m998.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.7.0 pymongo-4.10.1\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.10.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.7.0)\n",
            "Converting JSON data to CSV...\n",
            "Starting training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-91ddf07d5fd2>:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  trained_model.load_state_dict(torch.load(best_model_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting inference...\n",
            "Watching for real-time changes...\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install torchaudio\n",
        "!pip install torch-geometric\n",
        "!pip install pymongo\n",
        "!pip install --upgrade pymongo\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GraphConv\n",
        "from torch_geometric.data import Data\n",
        "from pymongo import MongoClient\n",
        "import random\n",
        "import json\n",
        "import csv\n",
        "import pandas as pd\n",
        "from bson import ObjectId\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import certifi\n",
        "from pymongo import MongoClient\n",
        "\n",
        "client = MongoClient(\n",
        "    \"mongodb+srv://gauravtemp123:GrnDPnMKIEsnBqGk@cluster0.eu8dw.mongodb.net/?retryWrites=true&w=majority\",\n",
        "    tlsCAFile=certifi.where(),\n",
        "    tls=True,\n",
        "    tlsAllowInvalidCertificates=False,\n",
        "    tlsAllowInvalidHostnames=False,\n",
        ")\n",
        "db = client[\"topology\"]\n",
        "devices_collection = db[\"devices\"]\n",
        "\n",
        "def json_to_csv(json_file, csv_file):\n",
        "    \"\"\"\n",
        "    Convert a JSON file to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        json_file (str): Path to the JSON file.\n",
        "        csv_file (str): Path to the CSV file.\n",
        "    \"\"\"\n",
        "    with open(json_file, 'r') as json_data:\n",
        "        data = json.load(json_data)\n",
        "\n",
        "    header = list(data[0].keys())\n",
        "\n",
        "    with open(csv_file, 'w', newline='') as csv_data:\n",
        "        writer = csv.DictWriter(csv_data, fieldnames=header)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(data)\n",
        "\n",
        "def fetch_device_data():\n",
        "    \"\"\"\n",
        "    Fetch device data from MongoDB.\n",
        "\n",
        "    Returns:\n",
        "        A list of device data.\n",
        "    \"\"\"\n",
        "    device_data_cursor = devices_collection.find()\n",
        "    device_data = []\n",
        "    for device in device_data_cursor:\n",
        "        device_data.append(device)\n",
        "    return device_data\n",
        "\n",
        "def convert_json_to_csv():\n",
        "    \"\"\"\n",
        "    Convert JSON data to CSV.\n",
        "    \"\"\"\n",
        "    device_data = fetch_device_data()\n",
        "    json_file = 'device_data.json'\n",
        "    csv_file = 'device_data.csv'\n",
        "\n",
        "    modified_device_data = [{k: str(v) if isinstance(v, ObjectId) else v for k, v in d.items()} for d in device_data]\n",
        "\n",
        "    with open(json_file, 'w') as file:\n",
        "        json.dump(modified_device_data, file)\n",
        "\n",
        "    json_to_csv(json_file, csv_file)\n",
        "\n",
        "def process_device_data_for_gnn(device):\n",
        "    \"\"\"\n",
        "    Process device data for GNN.\n",
        "\n",
        "    Args:\n",
        "        device (dict): Device data.\n",
        "\n",
        "    Returns:\n",
        "        A Data object containing node features and edge connections.\n",
        "    \"\"\"\n",
        "    ipAddress = device['ipAddress']\n",
        "    sysName = device.get('sysName', '')\n",
        "    routerID = device.get('routerID', '')\n",
        "    asNumber = device.get('asNumber', 0)\n",
        "\n",
        "    nodes = [ipAddress]  # For simplicity, Lets just start with the device itself\n",
        "    edges = []\n",
        "\n",
        "    for neighbor in device.get('eigrpNeighbors', []):\n",
        "        edges.append([ipAddress, neighbor['neighborIP']])  # Create edges between devices based on eigrpNeighbors\n",
        "\n",
        "        all_ips = set(sum(edges, []))  # Extract all unique IP addresses\n",
        "        ip_to_index = {ip: i for i, ip in enumerate(all_ips)}\n",
        "\n",
        "       # Convert edges to numerical indices using the mapping\n",
        "        numerical_edges = [[ip_to_index[ip1], ip_to_index[ip2]] for ip1, ip2 in edges]\n",
        "\n",
        "       # Now create the tensor from the numerical edges\n",
        "        edge_index = torch.tensor(numerical_edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "       # Create node features (we can add more complex features here from routingTable or other data)\n",
        "        features = torch.tensor([asNumber], dtype=torch.float).view(-1, 1)  # Simplified feature: AS number\n",
        "\n",
        "       # The Data class stores node features (x) and edge connections (edge_index)\n",
        "        gnn_data = Data(x=torch.zeros((len(ip_to_index), 1)), edge_index=edge_index)  # Specify the correct number of nodes\n",
        "\n",
        "        return gnn_data\n",
        "\n",
        "# GNN Model for Anomaly Detection\n",
        "class AnomalyDetectionGNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(AnomalyDetectionGNN, self).__init__()\n",
        "        self.conv1 = GraphConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GraphConv(hidden_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class DeviceDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Use a different column that exists in the DataFrame\n",
        "        self.device_data = self.data.iloc[:, 0]  # Use the first column\n",
        "        self.labels = self.data.iloc[:, -1]  # Use the last column\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.device_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        device_data = self.device_data.iloc[idx]\n",
        "        label = self.labels.iloc[idx]\n",
        "        return device_data, label\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_data(device_data):\n",
        "    if isinstance(device_data, tuple):\n",
        "        # Ignore non-numeric strings\n",
        "        device_data = torch.tensor(np.array([float(x) for x in device_data if x.replace('.', '', 1).replace('-', '', 1).isdigit()]))\n",
        "    else:\n",
        "        device_data = torch.tensor([float(device_data)])\n",
        "    return device_data\n",
        "\n",
        "def train_on_stream(csv_file, num_epochs=10):\n",
        "    # Create a data loader with a batch size of 1\n",
        "    data_loader = DataLoader(dataset=DeviceDataset(csv_file), batch_size=1, shuffle=True)\n",
        "\n",
        "    # Create the model, optimizer, and loss function\n",
        "    model = AnomalyDetectionGNN(input_dim=1, hidden_dim=16, output_dim=2).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch in data_loader:\n",
        "            # Assuming batch is a list of [device_data, label]\n",
        "            device_data, label = batch\n",
        "\n",
        "            # Check if device_data is not empty\n",
        "            if len(device_data) == 0:\n",
        "                continue\n",
        "\n",
        "            # Preprocess the data\n",
        "            device_data = preprocess_data(device_data)\n",
        "\n",
        "            # Check if device_data is not empty after preprocessing\n",
        "            if len(device_data) == 0:\n",
        "                continue\n",
        "\n",
        "            # Convert device_data and label to tensors\n",
        "            device_data = torch.tensor(device_data).unsqueeze(0).to(device, dtype=torch.float32)\n",
        "            if isinstance(label, str):\n",
        "                # Convert the label to a numerical value\n",
        "                label_map = {'label1': 0, 'label2': 1, 'label3': 2}  # Replace with your actual labels\n",
        "                label = torch.tensor(label_map.get(label, 0)).unsqueeze(0).to(device)\n",
        "            elif isinstance(label, tuple):\n",
        "                # Convert the tuple to a single value\n",
        "                if isinstance(label[0], str):\n",
        "                    label_map = {'label1': 0, 'label2': 1, 'label3': 2}  # Replace with your actual labels\n",
        "                    label = torch.tensor(label_map.get(label[0], 0)).unsqueeze(0).to(device)\n",
        "                else:\n",
        "                    try:\n",
        "                        label = torch.tensor(int(label[0])).unsqueeze(0).to(device)\n",
        "                    except ValueError:\n",
        "                        label = torch.tensor(0).unsqueeze(0).to(device)\n",
        "            else:\n",
        "                try:\n",
        "                    label = torch.tensor(int(label)).unsqueeze(0).to(device)\n",
        "                except ValueError:\n",
        "                    label = torch.tensor(0).unsqueeze(0).to(device)\n",
        "\n",
        "            # Create a dummy edge_index\n",
        "            edge_index = torch.tensor([[0], [0]], dtype=torch.long).to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(device_data, edge_index)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(output, label)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the model parameters\n",
        "            optimizer.step()\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(model.state_dict(), 'trained_model.pth')\n",
        "\n",
        "    return model, 'trained_model.pth'\n",
        "\n",
        "def infer_on_stream(model):\n",
        "    # Create a data loader with a batch size of 1\n",
        "    data_loader = DataLoader(dataset=DeviceDataset('device_data.csv'), batch_size=1, shuffle=False)\n",
        "\n",
        "    # Infer on the stream\n",
        "    for batch in data_loader:\n",
        "        # Assuming batch is a list of [device_data, label]\n",
        "        device_data, label = batch\n",
        "\n",
        "        # Preprocess the data\n",
        "        device_data = preprocess_data(device_data)\n",
        "\n",
        "        # Check if device_data is not empty\n",
        "        if len(device_data) == 0:\n",
        "            continue\n",
        "\n",
        "        # Convert device_data to a tensor\n",
        "        gnn_data = torch.tensor(device_data).unsqueeze(0).to(device, dtype=torch.float32)\n",
        "\n",
        "        # Create a dummy edge_index\n",
        "        edge_index = torch.tensor([[0], [0]], dtype=torch.long).to(device)\n",
        "\n",
        "        # Create a PyTorch Geometric data object\n",
        "        gnn_data = Data(x=gnn_data, edge_index=edge_index)\n",
        "\n",
        "        # Move the data to the device\n",
        "        gnn_data = gnn_data.to(device)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model(gnn_data.x, gnn_data.edge_index)\n",
        "\n",
        "        # Get the anomaly status\n",
        "        anomaly_status = torch.argmax(predictions, dim=1)\n",
        "\n",
        "        # Print the anomaly status\n",
        "        print(anomaly_status)\n",
        "\n",
        "def watch_device_data():\n",
        "    pipeline = [\n",
        "        {'$match': {'operationType': {'$in': ['insert', 'update', 'replace']}}}\n",
        "    ]\n",
        "    change_stream = devices_collection.watch(pipeline)\n",
        "\n",
        "    for change in change_stream:\n",
        "        print(\"Change detected:\", change)\n",
        "        device_data = change['fullDocument']\n",
        "        gnn_data = process_device_data_for_gnn(device_data).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predictions = model(gnn_data.x, gnn_data.edge_index)\n",
        "            anomaly_status = predictions.argmax(dim=1).item()\n",
        "\n",
        "            devices_collection.update_one(\n",
        "                {'ipAddress': device_data['ipAddress']},\n",
        "                {'$set': {'anomaly_detected': bool(anomaly_status)}}\n",
        "            )\n",
        "\n",
        "            if anomaly_status == 1:\n",
        "                print(f\"Real-time anomaly detected for device: {device_data['ipAddress']}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Converting JSON data to CSV...\")\n",
        "    convert_json_to_csv()\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    trained_model, best_model_path = train_on_stream('device_data.csv')\n",
        "\n",
        "    # Load the best model for inference\n",
        "    trained_model.load_state_dict(torch.load(best_model_path))\n",
        "    trained_model.to(device)\n",
        "\n",
        "    print(\"Starting inference...\")\n",
        "    infer_on_stream(trained_model)\n",
        "\n",
        "    print(\"Watching for real-time changes...\")\n",
        "    watch_device_data()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}